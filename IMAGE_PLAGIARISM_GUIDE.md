# üì∏ –†–£–ö–û–í–û–î–°–¢–í–û: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç

## üéØ –ó–ê–î–ê–ß–ê
–î–æ–±–∞–≤–∏—Ç—å –≤ —Å–∏—Å—Ç–µ–º—É –ø—Ä–æ–≤–µ—Ä–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (PDF/DOCX) –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç, —á—Ç–æ–±—ã –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ö–µ–º—ã, –≥—Ä–∞—Ñ–∏–∫–∏, —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –≤ –∫—É—Ä—Å–æ–≤—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö.

---

## üìã –ü–û–õ–ù–´–ô –ü–õ–ê–ù –†–ï–ê–õ–ò–ó–ê–¶–ò–ò

### –≠–¢–ê–ü 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (30 –º–∏–Ω)

#### 1.1 –î–æ–±–∞–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

**–û–±–Ω–æ–≤–∏—Ç—å `requirements.txt`:**
```python
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
Pillow==10.2.0              # –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
opencv-python==4.9.0.80     # –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ
imagehash==4.3.1            # –ü–µ—Ä—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ —Ö—ç—à–∏
PyMuPDF==1.23.0             # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ PDF (fitz)
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install Pillow opencv-python imagehash PyMuPDF
```

---

#### 1.2 –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª `Folder/documents/image_models.py`:**
```python
from django.db import models
from pgvector.django import VectorField

class DocumentImage(models.Model):
    """–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω–æ–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    document = models.ForeignKey('Document', on_delete=models.CASCADE, related_name='images')
    page_number = models.IntegerField(verbose_name='–ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
    image_index = models.IntegerField(verbose_name='–ò–Ω–¥–µ–∫—Å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ')
    
    # –§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_file = models.ImageField(upload_to='extracted_images/', blank=True, null=True)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    width = models.IntegerField()
    height = models.IntegerField()
    format = models.CharField(max_length=10)
    size_bytes = models.IntegerField()
    
    # –ü–µ—Ä—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ —Ö—ç—à–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    phash = models.BigIntegerField(null=True, verbose_name='Perceptual hash')
    dhash = models.BigIntegerField(null=True, verbose_name='Difference hash')
    ahash = models.BigIntegerField(null=True, verbose_name='Average hash')
    
    # CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
    embedding = VectorField(dimensions=512, null=True, blank=True)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        db_table = 'document_images'
        indexes = [
            models.Index(fields=['phash']),
            models.Index(fields=['document', 'page_number']),
        ]
        verbose_name = '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞'
        verbose_name_plural = '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'


class ImageSimilarity(models.Model):
    """–°—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    image1 = models.ForeignKey(DocumentImage, on_delete=models.CASCADE, related_name='similarities_as_img1')
    image2 = models.ForeignKey(DocumentImage, on_delete=models.CASCADE, related_name='similarities_as_img2')
    
    # –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏
    phash_distance = models.IntegerField(verbose_name='Hamming distance pHash')
    cosine_similarity = models.FloatField(verbose_name='–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ CLIP')
    ssim_score = models.FloatField(null=True, verbose_name='SSIM —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ')
    
    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
    is_duplicate = models.BooleanField(default=False)
    confidence = models.FloatField(default=0.0, verbose_name='–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0-1')
    
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        db_table = 'image_similarities'
        unique_together = [('image1', 'image2')]
        indexes = [
            models.Index(fields=['is_duplicate']),
            models.Index(fields=['-confidence']),
        ]
```

**–°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é:**
```bash
python Folder/manage.py makemigrations
python Folder/manage.py migrate
```

–¢–∞–∫–∂–µ –Ω—É–∂–Ω–æ **–≤–∫–ª—é—á–∏—Ç—å pgvector —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ** –µ—Å–ª–∏ –µ—â—ë –Ω–µ:
```sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;  -- –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
```

---

### –≠–¢–ê–ü 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (45 –º–∏–Ω)

#### 2.1 –°–æ–∑–¥–∞—Ç—å —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**–§–∞–π–ª `Folder/documents/image_extractor.py`:**
```python
"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ PDF –∏ DOCX
"""

import os
import io
from PIL import Image
import fitz  # PyMuPDF
from docx import Document as DocxDocument
from docx.oxml.table import CT_Tbl
from docx.oxml.text.paragraph import CT_P
from docx.table import _Cell, Table
from docx.text.paragraph import Paragraph


class ImageExtractor:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self, min_width=100, min_height=100):
        """
        Args:
            min_width: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            min_height: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        self.min_width = min_width
        self.min_height = min_height
    
    def extract_from_pdf(self, pdf_path, output_dir):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ PDF
        
        Returns:
            List[dict]: —Å–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        images = []
        
        try:
            doc = fitz.open(pdf_path)
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                image_list = page.get_images()
                
                for img_index, img_info in enumerate(image_list):
                    xref = img_info[0]
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    base_image = doc.extract_image(xref)
                    image_bytes = base_image["image"]
                    
                    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ PIL
                    image = Image.open(io.BytesIO(image_bytes))
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–∫–æ–Ω–∫–∏, –ø–∏–∫—Å–µ–ª–∏)
                    if image.width < self.min_width or image.height < self.min_height:
                        continue
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if image.mode not in ('RGB', 'L'):
                        image = image.convert('RGB')
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                    filename = f'page_{page_num+1}_img_{img_index+1}.png'
                    filepath = os.path.join(output_dir, filename)
                    image.save(filepath, 'PNG')
                    
                    images.append({
                        'page': page_num + 1,
                        'index': img_index + 1,
                        'path': filepath,
                        'width': image.width,
                        'height': image.height,
                        'format': image.format or 'PNG',
                        'size': len(image_bytes)
                    })
            
            doc.close()
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ PDF: {e}")
        
        return images
    
    def extract_from_docx(self, docx_path, output_dir):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ DOCX
        
        Returns:
            List[dict]: —Å–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        images = []
        
        try:
            doc = DocxDocument(docx_path)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ relationships
            for rel_id, rel in doc.part.rels.items():
                if "image" in rel.target_ref:
                    try:
                        image_bytes = rel.target_part.blob
                        image = Image.open(io.BytesIO(image_bytes))
                        
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ
                        if image.width < self.min_width or image.height < self.min_height:
                            continue
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                        if image.mode not in ('RGB', 'L'):
                            image = image.convert('RGB')
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                        filename = f'image_{len(images)+1}.png'
                        filepath = os.path.join(output_dir, filename)
                        image.save(filepath, 'PNG')
                        
                        images.append({
                            'page': 0,  # DOCX –Ω–µ –∏–º–µ–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü
                            'index': len(images) + 1,
                            'path': filepath,
                            'width': image.width,
                            'height': image.height,
                            'format': image.format or 'PNG',
                            'size': len(image_bytes)
                        })
                        
                    except Exception:
                        continue
        
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ DOCX: {e}")
        
        return images
    
    def extract(self, file_path, output_dir):
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        os.makedirs(output_dir, exist_ok=True)
        
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.pdf':
            return self.extract_from_pdf(file_path, output_dir)
        elif ext == '.docx':
            return self.extract_from_docx(file_path, output_dir)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {ext}")
```

---

### –≠–¢–ê–ü 3: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö—ç—à–µ–π –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (60 –º–∏–Ω)

#### 3.1 –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**–§–∞–π–ª `Folder/documents/image_processor.py`:**
```python
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
"""

import imagehash
from PIL import Image
import numpy as np
import cv2
from skimage.metrics import structural_similarity as ssim


class ImageProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.hash_size = 8  # –†–∞–∑–º–µ—Ä —Ö—ç—à–∞ (8x8 = 64 –±–∏—Ç–∞)
    
    def compute_hashes(self, image_path):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ —Ö—ç—à–∏
        
        Returns:
            dict: {'phash': int, 'dhash': int, 'ahash': int}
        """
        try:
            img = Image.open(image_path)
            
            return {
                'phash': int(str(imagehash.phash(img, hash_size=self.hash_size)), 16),
                'dhash': int(str(imagehash.dhash(img, hash_size=self.hash_size)), 16),
                'ahash': int(str(imagehash.average_hash(img, hash_size=self.hash_size)), 16),
            }
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö—ç—à–µ–π: {e}")
    
    @staticmethod
    def hamming_distance(hash1, hash2):
        """
        –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –•—ç–º–º–∏–Ω–≥–∞ –º–µ–∂–¥—É —Ö—ç—à–∞–º–∏
        
        Returns:
            int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–∞—é—â–∏—Ö—Å—è –±–∏—Ç
        """
        return bin(hash1 ^ hash2).count('1')
    
    def compute_clip_embedding(self, image_path, model=None):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥ (512-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä)
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            model: SentenceTransformer –º–æ–¥–µ–ª—å (–ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
            
        Returns:
            np.ndarray: –≤–µ–∫—Ç–æ—Ä (512,)
        """
        try:
            from sentence_transformers import SentenceTransformer
            
            if model is None:
                model = SentenceTransformer('clip-ViT-B-32')
            
            img = Image.open(image_path).convert('RGB')
            embedding = model.encode([img], convert_to_numpy=True, normalize_embeddings=True)[0]
            
            return embedding
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
    
    def compute_ssim(self, img1_path, img2_path):
        """
        –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (SSIM) –º–µ–∂–¥—É –¥–≤—É–º—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        
        Returns:
            float: –∑–Ω–∞—á–µ–Ω–∏–µ 0-1 (1 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã)
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)
            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
            height = min(img1.shape[0], img2.shape[0])
            width = min(img1.shape[1], img2.shape[1])
            
            img1 = cv2.resize(img1, (width, height))
            img2 = cv2.resize(img2, (width, height))
            
            # –í—ã—á–∏—Å–ª—è–µ–º SSIM
            score, _ = ssim(img1, img2, full=True)
            
            return float(score)
            
        except Exception as e:
            return 0.0
    
    def compare_images(self, img1_path, img2_path, use_clip=True):
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Returns:
            dict: {'phash_distance', 'ssim', 'clip_similarity', 'is_duplicate', 'confidence'}
        """
        result = {
            'phash_distance': None,
            'ssim': None,
            'clip_similarity': None,
            'is_duplicate': False,
            'confidence': 0.0
        }
        
        # 1. Perceptual hash (–±—ã—Å—Ç—Ä–æ)
        hashes1 = self.compute_hashes(img1_path)
        hashes2 = self.compute_hashes(img2_path)
        
        phash_dist = self.hamming_distance(hashes1['phash'], hashes2['phash'])
        result['phash_distance'] = phash_dist
        
        # –ï—Å–ª–∏ pHash —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ < 10, —Å—á–∏—Ç–∞–µ–º –ø–æ—Ö–æ–∂–∏–º–∏
        if phash_dist < 10:
            # 2. SSIM –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            result['ssim'] = self.compute_ssim(img1_path, img2_path)
            
            # 3. CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
            if use_clip and result['ssim'] > 0.7:
                emb1 = self.compute_clip_embedding(img1_path)
                emb2 = self.compute_clip_embedding(img2_path)
                result['clip_similarity'] = float(np.dot(emb1, emb2))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç
            if phash_dist <= 5 and result['ssim'] > 0.9:
                result['is_duplicate'] = True
                result['confidence'] = 0.95
            elif phash_dist <= 8 and result['ssim'] > 0.85:
                result['is_duplicate'] = True
                result['confidence'] = 0.85
        
        return result
```

---

### –≠–¢–ê–ü 4: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ Celery –∑–∞–¥–∞—á—É (30 –º–∏–Ω)

#### 4.1 –û–±–Ω–æ–≤–∏—Ç—å –∑–∞–¥–∞—á—É –æ–±—Ä–∞–±–æ—Ç–∫–∏

**–î–æ–±–∞–≤–∏—Ç—å –≤ `Folder/documents/tasks.py`:**
```python
from documents.image_extractor import ImageExtractor
from documents.image_processor import ImageProcessor
from documents.image_models import DocumentImage, ImageSimilarity


@shared_task(bind=True, max_retries=3)
def process_images_plagiarism(self, document_id):
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    
    Args:
        document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
    """
    try:
        doc = Document.objects.get(id=document_id)
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        file_path = doc.data.path
        output_dir = os.path.join('media', 'extracted_images', f'doc_{document_id}')
        
        extractor = ImageExtractor(min_width=150, min_height=150)
        extracted_images = extractor.extract(file_path, output_dir)
        
        if not extracted_images:
            return {'status': 'no_images', 'message': '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}
        
        # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        processor = ImageProcessor()
        clip_model = None  # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–¥–∏–Ω —Ä–∞–∑
        
        for img_data in extracted_images:
            # –í—ã—á–∏—Å–ª—è–µ–º —Ö—ç—à–∏
            hashes = processor.compute_hashes(img_data['path'])
            
            # –í—ã—á–∏—Å–ª—è–µ–º CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = processor.compute_clip_embedding(img_data['path'], clip_model)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            doc_image = DocumentImage.objects.create(
                document=doc,
                page_number=img_data['page'],
                image_index=img_data['index'],
                image_file=img_data['path'],
                width=img_data['width'],
                height=img_data['height'],
                format=img_data['format'],
                size_bytes=img_data['size'],
                phash=hashes['phash'],
                dhash=hashes['dhash'],
                ahash=hashes['ahash'],
                embedding=embedding.tolist()
            )
        
        # 3. –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        duplicates_found = find_similar_images(document_id)
        
        return {
            'status': 'success',
            'images_extracted': len(extracted_images),
            'duplicates_found': duplicates_found
        }
        
    except Exception as exc:
        raise self.retry(exc=exc)


def find_similar_images(document_id):
    """
    –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    
    Returns:
        int: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    doc_images = DocumentImage.objects.filter(document_id=document_id)
    processor = ImageProcessor()
    duplicates_count = 0
    
    for img in doc_images:
        # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ pHash (Hamming distance < 10)
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏–ª–∏ BK-tree
        similar_candidates = DocumentImage.objects.exclude(
            document_id=document_id
        ).exclude(
            phash__isnull=True
        )
        
        for candidate in similar_candidates:
            hamming = processor.hamming_distance(img.phash, candidate.phash)
            
            if hamming < 10:
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                comparison = processor.compare_images(
                    img.image_file.path,
                    candidate.image_file.path,
                    use_clip=True
                )
                
                if comparison['is_duplicate']:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    ImageSimilarity.objects.get_or_create(
                        image1=img,
                        image2=candidate,
                        defaults={
                            'phash_distance': hamming,
                            'cosine_similarity': comparison.get('clip_similarity', 0),
                            'ssim_score': comparison.get('ssim'),
                            'is_duplicate': True,
                            'confidence': comparison['confidence']
                        }
                    )
                    duplicates_count += 1
    
    return duplicates_count
```

#### 4.2 –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–¥–∞—á—É

**–û–±–Ω–æ–≤–∏—Ç—å `process_document_plagiarism` –≤ `tasks.py`:**
```python
# –ü–æ—Å–ª–µ —à–∞–≥–∞ 3 (–∞–Ω–∞–ª–∏–∑ –ø–ª–∞–≥–∏–∞—Ç–∞ —Ç–µ–∫—Å—Ç–∞)
# –î–æ–±–∞–≤–ª—è–µ–º —à–∞–≥ 4:

# –®–∞–≥ 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
process_images_plagiarism.delay(document_id)
```

---

### –≠–¢–ê–ü 5: API –∏ UI (45 –º–∏–Ω)

#### 5.1 –°–æ–∑–¥–∞—Ç—å view –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

**–î–æ–±–∞–≤–∏—Ç—å –≤ `Folder/documents/views.py`:**
```python
@login_required
def document_images(request, document_id):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏—Ö –∞–Ω–∞–ª–∏–∑"""
    doc = get_object_or_404(Document, id=document_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
    if not (request.user.is_staff or doc.user == request.user):
        return HttpResponseForbidden()
    
    images = DocumentImage.objects.filter(document=doc).order_by('page_number', 'image_index')
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—É—á–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ
    images_with_duplicates = []
    for img in images:
        duplicates = ImageSimilarity.objects.filter(
            image1=img,
            is_duplicate=True
        ).select_related('image2__document')[:5]
        
        images_with_duplicates.append({
            'image': img,
            'duplicates': duplicates
        })
    
    context = {
        'document': doc,
        'images_data': images_with_duplicates,
        'total_images': images.count()
    }
    
    return render(request, 'documents/document_images.html', context)
```

#### 5.2 –°–æ–∑–¥–∞—Ç—å —à–∞–±–ª–æ–Ω

**–§–∞–π–ª `Folder/documents/templates/documents/document_images.html`:**
```html
{% extends 'base.html' %}

{% block content %}
<div class="container">
    <h1>–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {{ document.name }}</h1>
    
    <div class="stats">
        <p>–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {{ total_images }}</p>
    </div>
    
    {% for item in images_data %}
    <div class="image-card">
        <div class="image-preview">
            <img src="{{ item.image.image_file.url }}" alt="Image {{ item.image.id }}">
            <p>–°—Ç—Ä–∞–Ω–∏—Ü–∞ {{ item.image.page_number }}, –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {{ item.image.image_index }}</p>
            <p>–†–∞–∑–º–µ—Ä: {{ item.image.width }}x{{ item.image.height }}</p>
        </div>
        
        {% if item.duplicates %}
        <div class="duplicates">
            <h3>‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({{ item.duplicates|length }}):</h3>
            {% for dup in item.duplicates %}
            <div class="duplicate-item">
                <img src="{{ dup.image2.image_file.url }}" alt="Duplicate">
                <p>
                    –î–æ–∫—É–º–µ–Ω—Ç: <a href="{% url 'documents:download_file' dup.image2.document.id %}">{{ dup.image2.document.name }}</a>
                </p>
                <p>–°—Ö–æ–∂–µ—Å—Ç—å: {{ dup.confidence|floatformat:2 }}</p>
                <p>SSIM: {{ dup.ssim_score|floatformat:3 }}</p>
            </div>
            {% endfor %}
        </div>
        {% else %}
        <p class="no-duplicates">‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ</p>
        {% endif %}
    </div>
    {% endfor %}
</div>
{% endblock %}
```

---

### –≠–¢–ê–ü 6: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ pgvector (30 –º–∏–Ω)

#### 6.1 –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pgvector –¥–ª—è CLIP –≤–µ–∫—Ç–æ—Ä–æ–≤

**–û–±–Ω–æ–≤–∏—Ç—å `find_similar_images()` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ANN (Approximate Nearest Neighbor):**
```python
def find_similar_images_fast(document_id, threshold=0.85):
    """
    –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ pgvector
    
    Args:
        document_id: ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
        threshold: –ø–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
    """
    from django.db import connection
    
    doc_images = DocumentImage.objects.filter(document_id=document_id)
    processor = ImageProcessor()
    duplicates_count = 0
    
    for img in doc_images:
        if img.embedding is None:
            continue
        
        # –ë—ã—Å—Ç—Ä—ã–π ANN –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ pgvector
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT id, document_id, 
                       embedding <=> %s::vector AS distance,
                       1 - (embedding <=> %s::vector) AS similarity
                FROM document_images
                WHERE id != %s
                  AND document_id != %s
                  AND embedding IS NOT NULL
                ORDER BY embedding <=> %s::vector
                LIMIT 10
            """, [img.embedding, img.embedding, img.id, document_id, img.embedding])
            
            results = cursor.fetchall()
        
        for similar_id, similar_doc_id, distance, similarity in results:
            if similarity >= threshold:
                candidate = DocumentImage.objects.get(id=similar_id)
                
                # –£—Ç–æ—á–Ω—è–µ–º —á–µ—Ä–µ–∑ pHash
                hamming = processor.hamming_distance(img.phash, candidate.phash)
                
                if hamming < 10:
                    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ SSIM
                    ssim_score = processor.compute_ssim(
                        img.image_file.path,
                        candidate.image_file.path
                    )
                    
                    if ssim_score > 0.85:
                        ImageSimilarity.objects.get_or_create(
                            image1=img,
                            image2=candidate,
                            defaults={
                                'phash_distance': hamming,
                                'cosine_similarity': similarity,
                                'ssim_score': ssim_score,
                                'is_duplicate': True,
                                'confidence': (similarity + ssim_score) / 2
                            }
                        )
                        duplicates_count += 1
    
    return duplicates_count
```

#### 6.2 –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã

**SQL –¥–ª—è pgvector:**
```sql
-- HNSW –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ ANN –ø–æ–∏—Å–∫–∞
CREATE INDEX IF NOT EXISTS image_embedding_hnsw_idx 
ON document_images 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- B-tree –∏–Ω–¥–µ–∫—Å –¥–ª—è pHash
CREATE INDEX IF NOT EXISTS image_phash_idx 
ON document_images (phash);
```

---

## üìä –û–ë–†–ê–ë–û–¢–ö–ê –¢–ê–ë–õ–ò–¶

### –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
‚úÖ –¢–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü **–£–ñ–ï –ò–ó–í–õ–ï–ö–ê–ï–¢–°–Ø** –≤ `docx_extractor.py`:
```python
# –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
for table in doc.tables:
    for row in table.rows:
        row_text = []
        for cell in row.cells:
            cell_text = cell.text.strip()
            if cell_text:
                row_text.append(cell_text)
        if row_text:
            tables_text.append(' | '.join(row_text))
```

### –£–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü:

#### 1. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü

**–°–æ–∑–¥–∞—Ç—å `Folder/documents/table_comparator.py`:**
```python
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–∞–±–ª–∏—Ü
"""

def extract_tables_structure(docx_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    
    Returns:
        List[dict]: [{
            'rows': int,
            'cols': int,
            'headers': List[str],
            'data': List[List[str]],
            'hash': str  # –•—ç—à —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        }]
    """
    from docx import Document as DocxDocument
    import hashlib
    
    doc = DocxDocument(docx_path)
    tables_data = []
    
    for table in doc.tables:
        rows_count = len(table.rows)
        cols_count = len(table.columns) if table.rows else 0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
        headers = []
        if rows_count > 0:
            headers = [cell.text.strip() for cell in table.rows[0].cells]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = []
        for row in table.rows[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
            row_data = [cell.text.strip() for cell in row.cells]
            data.append(row_data)
        
        # –•—ç—à —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (—Ä–∞–∑–º–µ—Ä—ã + –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        structure_str = f"{rows_count}x{cols_count}_{'-'.join(headers)}"
        table_hash = hashlib.md5(structure_str.encode()).hexdigest()
        
        tables_data.append({
            'rows': rows_count,
            'cols': cols_count,
            'headers': headers,
            'data': data,
            'hash': table_hash
        })
    
    return tables_data


def compare_tables(table1, table2):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–µ —Ç–∞–±–ª–∏—Ü—ã
    
    Returns:
        dict: {'structure_match': bool, 'data_similarity': float}
    """
    # 1. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    structure_match = (
        table1['rows'] == table2['rows'] and
        table1['cols'] == table2['cols'] and
        table1['headers'] == table2['headers']
    )
    
    # 2. –°—Ö–æ–¥—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
    if not structure_match:
        return {'structure_match': False, 'data_similarity': 0.0}
    
    total_cells = 0
    matching_cells = 0
    
    for row1, row2 in zip(table1['data'], table2['data']):
        for cell1, cell2 in zip(row1, row2):
            total_cells += 1
            if cell1.lower() == cell2.lower():
                matching_cells += 1
    
    data_similarity = matching_cells / total_cells if total_cells > 0 else 0.0
    
    return {
        'structure_match': True,
        'data_similarity': data_similarity
    }
```

---

## üé® –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –í UI

### 1. –î–æ–±–∞–≤–∏—Ç—å –∫–Ω–æ–ø–∫—É "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" –≤ –∫–∞–±–∏–Ω–µ—Ç–µ

```html
<!-- –í cab.html -->
<button type="button" class="more-btns__link">
  <a href="{% url 'documents:document_images' document.id %}">
    üì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({{ document.images.count }})
  </a>
</button>
```

### 2. –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫–∞—Ä—Ç–æ—á–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞

```html
<!-- –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π -->
{% if document.images.count > 0 %}
  {% with duplicates=document.images.filter(similarities_as_img1__is_duplicate=True).count %}
    {% if duplicates > 0 %}
      <span class="image-duplicates-warning">
        ‚ö†Ô∏è {{ duplicates }} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
      </span>
    {% endif %}
  {% endwith %}
{% endif %}
```

---

## üî• –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

**1. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ CLIP –º–æ–¥–µ–ª–∏**
```python
# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º
_clip_model_cache = None

def get_clip_model():
    global _clip_model_cache
    if _clip_model_cache is None:
        from sentence_transformers import SentenceTransformer
        _clip_model_cache = SentenceTransformer('clip-ViT-B-32')
    return _clip_model_cache
```

**2. –ë–∞—Ç—á–∏–Ω–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∏**
```python
# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–∞—á–∫–∞–º–∏ –ø–æ 10
for i in range(0, len(images), 10):
    batch = images[i:i+10]
    embeddings = model.encode([img for img in batch])
```

**3. pgvector ANN –∏–Ω–¥–µ–∫—Å**
- HNSW –∏–Ω–¥–µ–∫—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (~1000x –±—ã—Å—Ç—Ä–µ–µ)
- B-tree –¥–ª—è pHash (~100x –±—ã—Å—Ç—Ä–µ–µ)

**4. –§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞**
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π Celery –∑–∞–¥–∞—á–µ
- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∏–∂–µ —á–µ–º —É —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

---

## üìê –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ü–û–õ–ù–û–ô –°–ò–°–¢–ï–ú–´

```
–ó–∞–≥—Ä—É–∑–∫–∞ PDF/DOCX
        ‚îÇ
        ‚îú‚îÄ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¢–ï–ö–°–¢–ê
        ‚îÇ   ‚îú‚îÄ‚Üí –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (sentence-transformers)
        ‚îÇ   ‚îú‚îÄ‚Üí –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        ‚îÇ   ‚îî‚îÄ‚Üí –†–∞—Å—á—ë—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ ‚úÖ
        ‚îÇ
        ‚îî‚îÄ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
            ‚îú‚îÄ‚Üí –í—ã—á–∏—Å–ª–µ–Ω–∏–µ pHash/dHash/aHash (–±—ã—Å—Ç—Ä–æ)
            ‚îú‚îÄ‚Üí –í—ã—á–∏—Å–ª–µ–Ω–∏–µ CLIP embedding (–º–µ–¥–ª–µ–Ω–Ω–æ)
            ‚îú‚îÄ‚Üí –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö:
            ‚îÇ   ‚îú‚îÄ‚Üí pHash search (Hamming < 10)
            ‚îÇ   ‚îú‚îÄ‚Üí CLIP ANN search (pgvector)
            ‚îÇ   ‚îî‚îÄ‚Üí –†–µ—Ñ–∞–π–Ω —á–µ—Ä–µ–∑ SSIM
            ‚îî‚îÄ‚Üí –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ‚úÖ
```

---

## üíæ –ù–û–í–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ë–î

```sql
-- –¢–∞–±–ª–∏—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
CREATE TABLE document_images (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES "Document"(id),
    page_number INTEGER,
    image_index INTEGER,
    image_file VARCHAR(255),
    width INTEGER,
    height INTEGER,
    format VARCHAR(10),
    size_bytes INTEGER,
    phash BIGINT,          -- Perceptual hash
    dhash BIGINT,          -- Difference hash  
    ahash BIGINT,          -- Average hash
    embedding vector(512), -- CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥
    created_at TIMESTAMP
);

-- –ò–Ω–¥–µ–∫—Å—ã
CREATE INDEX image_phash_idx ON document_images (phash);
CREATE INDEX image_embedding_hnsw_idx ON document_images 
    USING hnsw (embedding vector_cosine_ops);

-- –¢–∞–±–ª–∏—Ü–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
CREATE TABLE image_similarities (
    id SERIAL PRIMARY KEY,
    image1_id INTEGER REFERENCES document_images(id),
    image2_id INTEGER REFERENCES document_images(id),
    phash_distance INTEGER,
    cosine_similarity FLOAT,
    ssim_score FLOAT,
    is_duplicate BOOLEAN,
    confidence FLOAT,
    created_at TIMESTAMP,
    UNIQUE(image1_id, image2_id)
);
```

---

## üéØ –ò–¢–û–ì–û–í–´–ô WORKFLOW

### –î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—É—Ä—Å–æ–≤—É—é —Ä–∞–±–æ—Ç—É (PDF/DOCX)
2. –°–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç ‚úÖ
4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã üì∏
5. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â–∏–π –æ—Ç—á—ë—Ç:
   - –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: 85%
   - –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 3
   - –†–∏—Å–∫: medium

### –î–ª—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è:
1. –í–∏–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
2. –ö–ª–∏–∫–∞–µ—Ç "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" ‚Üí –≤–∏–¥–∏—Ç –≤—Å–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏
3. –î–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤–∏–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –∏–∑ –¥—Ä—É–≥–∏—Ö —Ä–∞–±–æ—Ç
4. –ú–æ–∂–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç—å –≤–∏–∑—É–∞–ª—å–Ω–æ –∏ –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ

---

## üìä –¢–ê–ë–õ–ò–¶–´: –ö–ê–ö –û–ë–†–ê–ë–ê–¢–´–í–ê–Æ–¢–°–Ø

### –¢–µ–∫—É—â–∞—è —Å–∏—Å—Ç–µ–º–∞ (—Ç–µ–∫—Å—Ç):
–¢–∞–±–ª–∏—Ü—ã –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –∫–∞–∫ —Ç–µ–∫—Å—Ç: `–ó–∞–≥–æ–ª–æ–≤–æ–∫1 | –ó–∞–≥–æ–ª–æ–≤–æ–∫2 | ... \n –î–∞–Ω–Ω—ã–µ1 | –î–∞–Ω–Ω—ã–µ2 | ...`

–ó–∞—Ç–µ–º —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç—Å—è –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ shingles.

### –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ):

**1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ:**
- –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É: rows x cols
- –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
- –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –º–∞—Ç—Ä–∏—Ü—É

**2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ:**
```python
# –ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ (rows, cols, headers)
if tables_match_structure(t1, t2):
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —è—á–µ–µ–∫
    cell_similarity = compare_cells(t1.data, t2.data)
    
    if cell_similarity > 0.9:
        # –ü–õ–ê–ì–ò–ê–¢ - —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –≤—Å—è —Ç–∞–±–ª–∏—Ü–∞
        return 0% originality
    elif cell_similarity > 0.7:
        # –ü–û–î–û–ó–†–ï–ù–ò–ï - –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–∞–µ—Ç
        return low_originality
```

**3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
- –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —è—á–µ–µ–∫ –∫—Ä–∞—Å–Ω—ã–º
- Diff-view –¥–ª—è —Ç–∞–±–ª–∏—Ü
- –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —è—á–µ–π–∫–∞–º

---

## üöÄ –≠–¢–ê–ü–´ –í–ù–ï–î–†–ï–ù–ò–Ø

### –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è (1-2 –¥–Ω—è):
1. ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ PDF/DOCX
2. ‚úÖ pHash –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ
3. ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (Hamming < 5)
4. ‚úÖ UI –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞

### –°—Ä–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è (+2-3 –¥–Ω—è):
5. ‚úÖ CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
6. ‚úÖ pgvector ANN –ø–æ–∏—Å–∫
7. ‚úÖ SSIM —Ä–µ—Ñ–∞–π–Ω
8. ‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

### –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è (+3-5 –¥–Ω–µ–π):
9. ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
10. ‚úÖ Diff-view –¥–ª—è —Ç–∞–±–ª–∏—Ü
11. ‚úÖ ORB feature matching (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –ø–æ–≤–æ—Ä–æ—Ç–∞–º)
12. ‚úÖ –î–µ—Ç–µ–∫—Ü–∏—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π (—Ñ–∏–ª—å—Ç—Ä—ã, –∫–∞–¥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ)
13. ‚úÖ ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä "–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"

---

## üí° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò

### 1. –î–µ—Ç–µ–∫—Ü–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —ç—Ç–æ —Å–∫—Ä–∏–Ω—à–æ—Ç –∫–æ–¥–∞/—Ç–µ–∫—Å—Ç–∞, –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω—ë–º —á–µ—Ä–µ–∑ OCR (Tesseract).

### 2. Reverse image search
–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ (Google/Yandex Images API)

### 3. Watermark detection
–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–æ–≤/–ª–æ–≥–æ—Ç–∏–ø–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö

### 4. Chart/Graph recognition
–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –¥–∏–∞–≥—Ä–∞–º–º (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –∞ –Ω–µ –ø–∏–∫—Å–µ–ª–µ–π)

---

## ‚ö†Ô∏è –í–ê–ñ–ù–´–ï –ó–ê–ú–ï–ß–ê–ù–ò–Ø

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:
- **CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥:** ~200-500ms –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- **pHash:** ~10-50ms –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- **SSIM:** ~50-200ms –Ω–∞ –ø–∞—Ä—É
- **–î–ª—è 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:** ~30-60 —Å–µ–∫—É–Ω–¥ –æ–±—â–µ–µ –≤—Ä–µ–º—è

**–†–µ—à–µ–Ω–∏–µ:** Celery —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞.

### –•—Ä–∞–Ω–∏–ª–∏—â–µ:
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (~200 KB) √ó 10 —à—Ç √ó 1000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ = **~2 GB**
- CLIP –≤–µ–∫—Ç–æ—Ä (512 √ó 4 –±–∞–π—Ç–∞) √ó 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π √ó 1000 = **~20 MB**

**–†–µ—à–µ–Ω–∏–µ:** –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ–º–ø—Ä–µ—Å—Å–∏—è.

### –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è:
- –®–∞–±–ª–æ–Ω–Ω—ã–µ —Å—Ö–µ–º—ã –∏–∑ —É—á–µ–±–Ω–∏–∫–æ–≤ (–≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç)
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–∫–æ–Ω–∫–∏/–ª–æ–≥–æ—Ç–∏–ø—ã

**–†–µ—à–µ–Ω–∏–µ:** Whitelist –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –ø–æ—Ä–æ–≥ confidence > 0.9.

---

## ‚úÖ –ò–¢–û–ì

### DOCX –ø–æ–¥–¥–µ—Ä–∂–∫–∞ - –ì–û–¢–û–í–ê ‚úÖ
- –î–æ–±–∞–≤–ª–µ–Ω `python-docx`
- –°–æ–∑–¥–∞–Ω `docx_extractor.py`
- –û–±–Ω–æ–≤–ª–µ–Ω—ã —Ñ–æ—Ä–º—ã –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
- –û–±–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –®–∞–±–ª–æ–Ω—ã —Å –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ–º "PDF, DOCX"

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –ü–õ–ê–ù –ì–û–¢–û–í üìã
- –î–µ—Ç–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ö–æ–¥ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ pgvector
- UI/UX —Ä–µ—à–µ–Ω–∏—è
- –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏: 5-10 –¥–Ω–µ–π –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –¢–∞–±–ª–∏—Ü—ã - –£–ñ–ï –û–ë–†–ê–ë–ê–¢–´–í–ê–Æ–¢–°–Ø ‚úÖ
- –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è
- –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ shingles
- –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º

–ì–æ—Ç–æ–≤ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ - —Å–∫–∞–∂–∏—Ç–µ –∏ –Ω–∞—á–Ω—É!
